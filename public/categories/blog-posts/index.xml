<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog-Posts on A minimal Hugo website</title>
    <link>https://example.org/categories/blog-posts/</link>
    <description>Recent content in Blog-Posts on A minimal Hugo website</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Sep 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://example.org/categories/blog-posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Week 3</title>
      <link>https://example.org/post/2024/09/23/week-3/</link>
      <pubDate>Mon, 23 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://example.org/post/2024/09/23/week-3/</guid>
      <description>&lt;p&gt;So far, we’ve been looking at predictions using data about previous elections, relative to basic&#xA;factors (incumbency, party) as well as to measures of economic well-being. However, we have a&#xA;much more recent dataset into which we have not yet tapped: the thousands of public opinion&#xA;polls that are conducted each year. Through the principles of sampling, polls appear to be&#xA;relatively good estimates; a random subset of the population will behave, on average, similarly&#xA;to the whole population. But this doesn’t mean polls have always gotten it right in practice; one&#xA;of the most significant examples of this was 2016, where by and large, the polls famously&#xA;predicted the wrong winner.&#xA;This leads us to explore the week’s guiding question: How can we best use polls to predict&#xA;election outcomes?&#xA;To understand the polls’ behavior so far in the 2024 cycle, I visualized the variation over time&#xA;and against key events:&#xA;First, I added key events in 2024 to help understand the poll variation we’ve seen so far this&#xA;year. In context of the timings, the major jump in Democratic approval in this graph is explained&#xA;by Biden’s exit from the race on July 21st and subsequent handoff to Vice President Harris.&#xA;Both parties’ approval rates have most recently been increasing, which could potentially be&#xA;related to the recent dropout of independent candidate Robert F. Kennedy Jr. and the influx of&#xA;third-party voters resigning themselves to approving of one of the two major parties.&#xA;Next, I used some of the machine learning methods we went over in lab to create predictions&#xA;based on the polls. We had learned how to create predictions based on the national polls, using&#xA;the regularized elasticnet regression method, which resulted in a prediction of 51.79268% for&#xA;Harris and 50.65879% for Trump.&#xA;To build on this initial foundation, I tried looking at state polls. For the state I had chosen to&#xA;analyze, Pennsylvania, I found that the state poll data only had one or two polls for each&#xA;election year. This was not enough data to constitute a good training set, so I considered my&#xA;other options. One would be using all the state data in aggregate and indiscriminately, but I&#xA;didn’t think that would produce a very meaningful estimate, as which state a poll came from&#xA;would have no effect on how it was weighted. Another option would be to collect more data on&#xA;state-specific polls, which could be a good approach in the future.&#xA;I then shifted my focus to creating a model based on the assessments of poll quality and their&#xA;resulting performance in 2020, so that I could assign a predicted error to each poll based on&#xA;correlations with its FiveThirtyEight graded score and potentially other poll quality factors. I&#xA;created an ordinary least squares model to achieve this for 2020. I converted the letter grades&#xA;to a numeric scale, so that I could perform a linear regression on the poll grades. This found a&#xA;correlation between poll grades and error, as visualized below (1 = best; 10 = worst), but FTE&#xA;has since changed its grading system from a letter grade to a different numeric scale; therefore,&#xA;I couldn&amp;rsquo;t reapply this model to 2024 data accurately.&#xA;If I could establish a direct conversion rate between the old and new FTE scales, I would be&#xA;able to use this scale to convert the 2020 correlation data to a 2024 prediction data.&#xA;In the future, I would see if I could find the conversion scale so that I could actually use this to&#xA;create an updated 2024 prediction model!&lt;/p&gt;</description>
    </item>
    <item>
      <title>Week 2</title>
      <link>https://example.org/post/2024/09/16/week-2/</link>
      <pubDate>Mon, 16 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://example.org/post/2024/09/16/week-2/</guid>
      <description>&lt;p&gt;Although last week’s debate drew many viewers and much online discussion, some wondered&#xA;how much effect it would really have on the outcome of the 2024 election. After all, some&#xA;longstanding theories suggest that a candidate’s campaign strategy, debate performance, and&#xA;other actions all fall short to economic variables in the task of prediction. After all, if a voter isn’t&#xA;doing well economically, wouldn’t that motivate them to seek out a change? And if they are&#xA;doing well, shouldn’t they vote for the incumbent in their own self-interest?&#xA;The theory of “pocketbook voting” suggests exactly this: that people vote based on their direct&#xA;economic situations. In this theory, the economy is the principal variable in an election, and&#xA;should therefore be able to predict the results.&#xA;This week, we set out to answer the question: Can we predict election outcomes using only the&#xA;state of the economy? If so, how well?&#xA;Specifically, I looked at GDP and RDI (real disposable income), the former of which is a&#xA;measure of nationwide economic productivity and the latter of which represents how much&#xA;direct spending power people have.&#xA;Following the idea of pocketbook voting most closely, the variable most tightly correlated with&#xA;incumbent votes should be RDI. However, GDP is also often used as a predictive measure&#xA;because it indicates the overall state of the economy. I compared both measures in a series of&#xA;model fits and visualizations that focused on mapping previous presidential elections to&#xA;economic conditions and incumbent vote shares.&#xA;I also sometimes omitted the case of 2020: as shown in the below two graphs, the change to&#xA;the economy caused by the COVID-19 pandemic was unprecedented and made it a significant&#xA;outlier.&#xA;The following scatter plots graph these two economic measures against the incumbent party’s&#xA;popular vote share.&#xA;Including 2020:&#xA;Excluding 2020:&#xA;Using linear regressions, I created lines of best fit as follows for the 2020-excluded datasets:&#xA;Although they both appear positively correlated, the statistics ended up having different&#xA;significance values. Focusing only on the 2020-excluded values, here are some of the statistics&#xA;for GDP and RDI (all when compared to popular vote share):&#xA;Slope&#xA;Coefficient&#xA;Correlation R squared P value&#xA;GDP 0.7366 0.569918 0.3248066 0.0135&#xA;(significant!)&#xA;RDI 0.4604 0.3338966 0.1114869 0.176 (not!)&#xA;Based on these numbers, it’s clear that GDP is a more significant or substantive predictor of&#xA;popular vote election results. However, I wondered if using both variables together could be an&#xA;even better predictor.&#xA;As a result, I also created a combined multivariate linear regression between these two&#xA;variables, which had interesting results.&#xA;Coefficients:&#xA;Estimate Std. Error t value Pr(&amp;gt;|t|)&#xA;(Intercept) 49.40880 1.75347 28.178 2.1e-14 ***&#xA;RDPI_growth_quarterly -0.01269 0.36442 -0.035 0.9727&#xA;GDP_growth_quarterly 0.74367 0.34155 2.177 0.0458 *&#xA;When controlling for GDP, the coefficient for RDI was actually negative!&#xA;I also plotted in-sample error for each of the three models (GDP, RDI, Both), in both line charts&#xA;and histograms, as shown:&#xA;The histograms suggest that using GDP alone appears to create the most accurate predictions,&#xA;so the final prediction for 2024 will also be based on that model:&#xA;The model predicts that the incumbent party (the Democrats) will receive 51.58486% of the&#xA;popular vote in the 2024 presidential election.&#xA;Overall, although there is a somewhat significant correlation between GDP and election results,&#xA;using economic situations alone does not create a perfect model; there are various outliers,&#xA;especially the year 2020. There are many other reasons that 2024 could be an outlier (Biden&#xA;stepping down and Harris stepping in last-minute; the outlier-filled candidacy of Trump; the road&#xA;to economic recovery from COVID) and thus the usual economic models may not work as well&#xA;for it as they have for past elections.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Week 1</title>
      <link>https://example.org/post/2024/09/09/week-1/</link>
      <pubDate>Mon, 09 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://example.org/post/2024/09/09/week-1/</guid>
      <description>&lt;p&gt;Guiding Questions&#xA;This week, we set out to answer two key questions about presidential elections in the United States.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;How competitive are presidential elections in the United States?&lt;/li&gt;&#xA;&lt;li&gt;Which states vote blue/red and how consistently?&#xA;There are many ways to approach these questions, especially with predictive ends in mind. Is it possible to gather enough data points about a state to accurately understand the likelihood of its individual outcome in the upcoming election?&#xA;Analysis &amp;amp; Visualization&#xA;In lab this week, we explored popular vote data and electoral college data in order to understand these concepts.&#xA;To understand the first question, the competitiveness of presidential elections, one of the most common auxiliary questions could be how close elections are. We can look into this by examining the two-party popular vote share of each candidate, in which the closest election would have 50% for each candidate. The following graph we created in lab can represent the competitiveness of elections over time:&#xA;This suggests broadly that elections in recent years have been closer, and likely more competitive as a result, while previous elections had very large margins of victory, even if they alternated each term.&#xA;Other measures of competitiveness, which could be implemented in the future, include advertising dollars spent on campaigning, or other measures of the intensity of campaigns. In addition, an aspect of competitiveness that this graph does not consider is the number of candidates; although United States elections frequently have two truly viable candidates, primary competitiveness could be another interesting variable to analyze. (for example, the 2024 Democratic presidential primary was less competitive, while 2016 was very competitive - analyzing data points like this across a large number of past elections could be interesting.)&#xA;To answer the second question, using electoral map data could help understand which states vote blue and red and how frequently. The following visualization we created in lab represents these numbers for the popular vote in each state in the most recent presidential election in 2020:&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;To create a finalized electoral prediction, I followed the example set in the lab for an electoral vote prediction, based on ¾ of the previous vote share added to ¼ of the vote share from two elections back, and then graph the prediction across states using a color scale to suggest a predicted margin of victory.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
